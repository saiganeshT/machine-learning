{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mez6xmUSEay7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.max_rows', 50) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3o7G0Wrey9J",
        "outputId": "62214c99-6f2b-4259-cde1-d8c5a4a510fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1BfYKBUHOg1",
        "outputId": "9ae5b45f-bd04-4beb-8060-15275fbc8e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "newdata = pd.read_csv('/content/drive/My Drive/project/annotations_final.csv', sep=\"\\t\")\n",
        "newdata.info()\n",
        "newdata.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25863 entries, 0 to 25862\n",
            "Columns: 190 entries, clip_id to mp3_path\n",
            "dtypes: int64(189), object(1)\n",
            "memory usage: 37.5+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['clip_id', 'no voice', 'singer', 'duet', 'plucking', 'hard rock',\n",
              "       'world', 'bongos', 'harpsichord', 'female singing',\n",
              "       ...\n",
              "       'rap', 'metal', 'hip hop', 'quick', 'water', 'baroque', 'women',\n",
              "       'fiddle', 'english', 'mp3_path'],\n",
              "      dtype='object', length=190)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhK55gLzHz0B",
        "outputId": "5ca89208-9464-4298-b70f-54eec8f3c6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "clip_id = newdata[[\"clip_id\", \"mp3_path\"]].as_matrix()[:,0]\n",
        "mp3_path = newdata[[\"clip_id\", \"mp3_path\"]].as_matrix()[:,1]\n",
        "\n",
        "# list all the similar genres to decrease the number of labels\n",
        "synonyms = [['beat', 'beats'],\n",
        "            ['chant', 'chanting'],\n",
        "            ['choir', 'choral'],\n",
        "            ['classical', 'clasical', 'classic'],\n",
        "            ['drum', 'drums'],\n",
        "            ['electro', 'electronic', 'electronica', 'electric'],\n",
        "            ['fast', 'fast beat', 'quick'],\n",
        "            ['female', 'female singer', 'female singing', 'female vocals', 'female vocal', 'female voice', 'woman', 'woman singing', 'women'],\n",
        "            ['flute', 'flutes'],\n",
        "            ['guitar', 'guitars'],\n",
        "            ['hard', 'hard rock'],\n",
        "            ['harpsichord', 'harpsicord'],\n",
        "            ['heavy', 'heavy metal', 'metal'],\n",
        "            ['horn', 'horns'],\n",
        "            ['india', 'indian'],\n",
        "            ['jazz', 'jazzy'],\n",
        "            ['male', 'male singer', 'male vocal', 'male vocals', 'male voice', 'man', 'man singing', 'men'],\n",
        "            ['no beat', 'no drums'],\n",
        "            ['no singer', 'no singing', 'no vocal','no vocals', 'no voice', 'no voices', 'instrumental'],\n",
        "            ['opera', 'operatic'],\n",
        "            ['orchestra', 'orchestral'],\n",
        "            ['quiet', 'silence'],\n",
        "            ['singer', 'singing'],\n",
        "            ['space', 'spacey'],\n",
        "            ['string', 'strings'],\n",
        "            ['synth', 'synthesizer'],\n",
        "            ['violin', 'violins'],\n",
        "            ['vocal', 'vocals', 'voice', 'voices'],\n",
        "            ['strange', 'weird']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwXNZy6aIzcP"
      },
      "source": [
        "# apply the new genre as the first genre from the synonyms for a correspoding genre\n",
        "for synonym_list in synonyms:\n",
        "    newdata[synonym_list[0]] = newdata[synonym_list].max(axis=1)\n",
        "    newdata.drop(synonym_list[1:], axis=1, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ryPdUYnK3SW"
      },
      "source": [
        "# Drop the mp3_path tag from the dataframe\n",
        "newdata.drop('mp3_path', axis=1, inplace=True)\n",
        "newdata.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qch1wlzuPa0d"
      },
      "source": [
        "root = \"/content/drive/My Drive/project/\"\n",
        "path = root+\"dataset_clip_id_mp3/\"\n",
        "root2 = \"/content/data/\"\n",
        "\n",
        "data = pd.read_csv(root+'annotations.csv')\n",
        "clip_ids_all = data['clip_id']\n",
        "\n",
        "# rename and re-order files\n",
        "for id in range(25863):\n",
        "   print(clip_id[id], mp3_path[id])\n",
        "   src = root+\"/music\" + \"/\" + mp3_path[id]\n",
        "   dest = root + \"/dataset_clip_id_mp3/\" + str(clip_id[id]) + \".mp3\"\n",
        "   shutil.copy2(src,dest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu6DlW6iUiQC"
      },
      "source": [
        "# Convert all the mp3 files into their corresponding mel-spectrograms (melgrams).\n",
        "\n",
        "# Audio preprocessing function\n",
        "def compute_melgram(audio_path):\n",
        "\n",
        "    # mel-spectrogram parameters\n",
        "    SR = 12000\n",
        "    N_FFT = 512\n",
        "    N_MELS = 96\n",
        "    HOP_LEN = 256\n",
        "    DURA = 29.12  # to make it 1366 frame..\n",
        "\n",
        "    src, sr = librosa.load(audio_path, sr=SR)  # whole signal\n",
        "    n_sample = src.shape[0]\n",
        "    n_sample_fit = int(DURA*SR)\n",
        "\n",
        "    if n_sample < n_sample_fit:  # if too short\n",
        "        src = np.hstack((src, np.zeros((int(DURA*SR) - n_sample,))))\n",
        "    elif n_sample > n_sample_fit:  # if too long\n",
        "        src = src[int((n_sample-n_sample_fit)/2):int((n_sample+n_sample_fit)/2)]\n",
        "    logam = librosa.amplitude_to_db\n",
        "    melgram = librosa.feature.melspectrogram\n",
        "    ret = logam(melgram(y=src, sr=SR, hop_length=HOP_LEN,\n",
        "                        n_fft=N_FFT, n_mels=N_MELS)**2,\n",
        "                ref=1.0)\n",
        "    ret = ret[np.newaxis, :]\n",
        "    ret = np.swapaxes(ret, 1, 2)\n",
        "    return ret\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crHBE0rhypZJ"
      },
      "source": [
        "start = 863\n",
        "end = 1863\n",
        "cur_batch = 1\n",
        "\n",
        "while cur_batch <= 25:\n",
        "\n",
        "    # Variable to save the mp3 files that don't work\n",
        "    files_that_dont_work=[]\n",
        "    os.chdir(root + '/dataset_clip_id_mp3/')\n",
        "    specs_clip_ids = [] #ch\n",
        "    dataset = np.zeros((0, 1366, 96)) #ch\n",
        "    arr2 = []\n",
        "    for ele in clip_ids_all:\n",
        "      arr2.append(str(ele)+\".mp3\")\n",
        "\n",
        "    arr3 = arr2[start:end]\n",
        "    name = \"batch\"+str(cur_batch)\n",
        "\n",
        "\n",
        "    for audio in arr3:\n",
        "        #audio_paths.append(os.path.abspath(fname))\n",
        "        #if os.path.isfile(root + 'dataset_clip_id_melgram/' + str(os.path.splitext(audio_path)[0]) + '.npy'):\n",
        "        #    print(\"exist!\")\n",
        "        #    continue    \n",
        "                #if str(os.path.splitext(audio_path)[1]) == \".mp3\":\n",
        "                    try:\n",
        "                        melgram = compute_melgram(root + '/dataset_clip_id_mp3/'+audio)\n",
        "                        dest = root2+name\n",
        "                        dataset = np.concatenate((dataset, melgram), axis = 0)\n",
        "                        #current_iteration = current_iteration + 1\n",
        "                        specs_clip_ids.append(int(os.path.splitext(audio)[0]))\n",
        "                        #if current_iteration == batchsize:\n",
        "                        #np.save(dest, melgram)\n",
        "                    except EOFError:\n",
        "                        files_that_dont_work.append(audio)\n",
        "                        continue\n",
        "    np.save(dest, dataset)\n",
        "    clipIds = np.array(arr3)\n",
        "    path = root+name+'_clip_ids'\n",
        "    np.save(path, clipIds)\n",
        "    print(\"files that didn't work\")\n",
        "    print(files_that_dont_work)\n",
        "    #print(specs_clip_ids)\n",
        "    #print(len(specs_clip_ids))\n",
        "\n",
        "    saved_clip_ids = np.load(path+'.npy', allow_pickle=True)\n",
        "    #print(len(saved_clip_ids))\n",
        "    clips = []\n",
        "    for clip in saved_clip_ids:\n",
        "      clips.append(int(os.path.splitext(clip)[0]))\n",
        "    #print(clips)\n",
        "    #len(set(list(specs_clip_ids)).difference(clips))\n",
        "\n",
        "    selected_data = data[start:end]\n",
        "\n",
        "    for song in files_that_dont_work:\n",
        "      selected_data = selected_data[selected_data['clip_id'] != int(os.path.splitext(song)[0])]\n",
        "\n",
        "    selected_data.drop('Unnamed: 0', axis = 1, inplace= True)\n",
        "    selected_data.drop('clip_id', axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "    y_values = selected_data.to_numpy()\n",
        "    np.save(root2+name+'_y', y_values)\n",
        "\n",
        "    print(name)\n",
        "    print(y_values.shape)\n",
        "    print(dataset.shape)\n",
        "\n",
        "    #labels = selected_data.columns\n",
        "    #np.save(root+'labels', labels)\n",
        "    #print(labels)\n",
        "    #len(labels)\n",
        "\n",
        "    start = end\n",
        "    end = end + 1000\n",
        "    cur_batch = cur_batch+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yScZAHs0s_EZ",
        "outputId": "8b77ce9d-5f42-41aa-ff20-a0079b3b31b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "labels = np.load(root+'labels.npy', allow_pickle=True)\n",
        "print(labels.shape)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(134,)\n",
            "['singer' 'duet' 'plucking' 'world' 'bongos' 'harpsichord' 'sitar'\n",
            " 'chorus' 'female opera' 'clarinet' 'heavy' 'woodwind' 'funky'\n",
            " 'no strings' 'chimes' 'foreign' 'no piano' 'classical' 'female'\n",
            " 'soft rock' 'eerie' 'jazz' 'guitar' 'quiet' 'no beat' 'banjo' 'solo'\n",
            " 'folk' 'wind' 'happy' 'ambient' 'new age' 'synth' 'funk' 'middle eastern'\n",
            " 'trumpet' 'percussion' 'drum' 'airy' 'repetitive' 'birds' 'space' 'bass'\n",
            " 'medieval' 'girl' 'keyboard' 'acoustic' 'loud' 'string' 'not classical'\n",
            " 'no violin' 'not rock' 'no guitar' 'organ' 'talking' 'opera' 'soprano'\n",
            " 'fast' 'acoustic guitar' 'electric guitar' 'classical guitar' 'country'\n",
            " 'violin' 'electro' 'reggae' 'tribal' 'dark' 'male opera' 'irish' 'horn'\n",
            " 'arabic' 'lol' 'low' 'trance' 'chant' 'strange' 'drone' 'modern' 'disco'\n",
            " 'bells' 'deep' 'industrial' 'hard' 'harp' 'no flute' 'jungle' 'pop'\n",
            " 'lute' 'oboe' 'mellow' 'viola' 'light' 'echo' 'piano' 'celtic'\n",
            " 'orchestra' 'eastern' 'old' 'punk' 'spanish' 'sad' 'sax' 'slow' 'male'\n",
            " 'blues' 'vocal' 'no singer' 'scary' 'india' 'rock' 'dance' 'piano solo'\n",
            " 'cello' 'calm' 'different' 'techno' 'clapping' 'house' 'monks' 'flute'\n",
            " 'not opera' 'not english' 'oriental' 'beat' 'upbeat' 'soft' 'noise'\n",
            " 'choir' 'rap' 'hip hop' 'water' 'baroque' 'fiddle' 'english']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}